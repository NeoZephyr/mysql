## 索引模型

### 哈希
1. 只适用于等值查询，区间查询会很慢
2. 在有大量重复键的情况下，效率不高

### 有序数组索引
1. 适用于等值查询、区间查询
2. 更新数据成本太高，适用于存储静态数据

### 二叉搜索树
1. 当数据量大的时候，树的高度会比较高，查询会比较慢
2. 每个节点只存储一个记录，可能导致一次查询有很多次磁盘 IO

### B 树
1. 不再是二叉搜索，而是 m 叉搜索，高度能够大大降低
2. 叶子节点与非叶子节点，都存储数据
3. 通过中序遍历，可以获得所有节点

### B+ 树
1. 非叶子节点不再存储数据，数据只存储在同一层的叶子节点上。因此非叶子节点只存储 key，同样大小的磁盘页能比 B 树存储更多索引
2. 叶子之间，增加了链表，可以通过遍历获取所有节点，不再需要中序遍历；范围查找，定位 min 与 max 之后，中间叶子节点，就是结果集
3. 叶子节点存储实际记录行，记录行相对比较紧密的存储，适合大数据量磁盘存储；非叶子节点存储记录的PK，用于查询加速，适合内存存储

## 索引实现

### `MyISAM`
1. 主键索引与普通索引没有本质差异
2. 只有非聚集索引，即索引与数据是分开存储的
3. 主键索引的叶子节点，存储主键与对应行记录的指针；普通索引的叶子结点，存储索引列与对应行记录的指针

### `InnoDb`
1. 每一个表都会有聚集索引（主键索引），且只能有一个
  1.1 如果表定义了主键，则主键就是聚集索引
  1.2 如果表没有定义主键，则第一个非空 `unique` 列是聚集索引
  1.3 如果以上条件都不满足，则会创建一个隐藏的 `row id` 作为聚集索引

2. 主键索引的叶子节点会存储主键与数据行，即数据与索引在一起；非主键索引（二级索引）只会存储主键值。因此基于非主键索引的查询需要先扫描非主键索引树以找到对应主键键值，然后再扫描主键索引树，这个过程称为回表

3. 不建议使用类似字符串这种较长的列做主键，因为所有的普通索引都会存储主键，过长的主键会导致普通索引过于庞大

4. 当插入新值时，为了保持索引的有序性，要进行必要的维护。以 `id` 索引为例，插入一条记录，如果 `id` 要插入的索引数据页满了，就需要申请新的数据页，进行分页处理。同理，如果删除了数据，数据页的利用率变低，就需要合并

5. 建议使用趋势递增的列作为主键，因为是递增的，每次插入都是追加操作，这样不至于插入记录时引起大量索引分裂、记录行移动

普通索引重建
```sql
alter table T drop index k;
alter table T add index(k);
```
由于普通索引依赖主键索引，所以不论是删除主键还是创建主键，都会将整个表重建
```sql
alter table T drop primary key;
alter table T add primary key(id);
```
正确地重建主键索引
```sql
alter table T engine=InnoDB
```

顺序应是先删除 k 索引，主键索引；然后再创建主键索引和 k 索引

## 索引回表
```sql
select * from user where age between 15 and 20;
```
以上查询会经历一下步骤：
1. 在 age 索引树上找到 age = 15 的记录，取得 id
2. 根据 id 查询 id 索引树，获取行数据
3. 再在 age 索引树上面取下一个值 age = 16 的记录，获取 id
4. 根据 id 查询 id 索引树，获取行数据
5. 重复上述操作，直至 age 不符合条件

在以上过程中，回到主键索引树搜索的过程，我们称为回表。这是因为查询结果所需的数据只有主键索引上有，所以不得不回表。但如果执行语句是这样的：
```sql
select id from user where age between 15 and 20;
```
那么这时只需要查 id 的值，而 id 的值已经在 age 索引树上，因此可以直接提供查询结果，不需要回表。此时称 age 索引为覆盖索引。在数据库索引建立过程中，可以通过建立冗余索引来支持覆盖索引，达到优化查询的目的

### 索引下推
```sql
select * from user where name like '张 %' and age = 10 and ismale = 1;
```
假设已有联合索引 (name, age)，则该语句在搜索索引树的时候，只能用 `name` 索引，根据 `name` 索引找到第一个满足条件的记录后，然后从找到的第一个满足条件的记录开始一个个回表。到主键索引上找出数据行，再对 `age`、`ismale` 字段值。比如说，根据 `name` 索引查看到的满足条件的记录如下，需要回表四次
```
name: 张六, age: 30
name: 张三, age: 10
name: 张三, age: 10
name: 张三, age: 20
```

MySQL 5.6 引入的索引下推优化（index condition pushdown)，可以在索引遍历过程中，对索引中包含的字段先做判断，直接过滤掉不满足条件的记录，减少回表次数。比如说，在根据 `name` 索引查看到满足条件的记录之后，同时筛选出 `age` 为 10 的记录，这样就只需要回表两次

## 索引组合
索引 (age, name) + (name) 相比于 (name, age) + (age) 效果一样，但所需空间较多

```sql
CREATE TABLE `geek` (
  `a` int(11) NOT NULL,
  `b` int(11) NOT NULL,
  `c` int(11) NOT NULL,
  `d` int(11) NOT NULL,
  PRIMARY KEY (`a`,`b`),
  KEY `c` (`c`),
  KEY `ca` (`c`,`a`),
  KEY `cb` (`c`,`b`)
) ENGINE=InnoDB;
```
```sql
select * from geek where c = N order by a limit 1;
select * from geek where c = N order by b limit 1;
```

主键索引组织顺序相当于 `order by a, b`，先按 a 排序，再按 b 排序；索引 ca 组织顺序是先按 c 排序，再按 a 排序，同时记录主键中 b 部分，索引结构与索引 c 一样；索引 cb 组织顺序是先按 c 排序，再按 b 排序，同时记录主键中 a 部分。因此，可以看出，索引 c 与索引 ca 效果一样，可以去除索引 ca

## 唯一索引
唯一索引与普通索引有一些不同之处，首先是查询过程：
```sql
select id from user where k = 5;
```
1. 如果 k 是普通索引，在查找到满足条件的第一个记录后，需要继续查找下一个记录，直到碰到第一个不满足条件的记录为止
2. 如果 k 是唯一索引，再查找到满足条件的第一个记录后，就会停止继续检索

由于 Innodb 是按照数据页为单位进行读写的，也就是说，当需要读取一条记录时，并不是读取单条记录，而是以页为单位，整体读入内存。再 Innodb 中，数据页默认大小为 16kB。正因为这个特性，使用普通索引时，满足 `k = 5` 条件的记录大概率会在同一个数据页中，再读取下一个满足条件的记录时带来的性能消耗可以忽略

再看唯一索引与普通索引在更新过程中的差异：
当更新记录时，如果记录所在数据页在内存中，就直接更新；否则，在不影响数据一致性的前提下，Innodb 会将这些更新缓存在 change buffer 中，从而减少磁盘 IO。当下次需要访问对应数据页的时候，将数据页读入内存，然后执行 change buffer 中与这个数据页有关的操作。（change buffer 是持久化数据，也会被写入磁盘）

```sql
insert into user(k) values (4);
```
1. 如果 k 是普通索引，如果要更新目标页不在内存，则将更新记录到 change buffer；如果更新目标页在内存，则更新内存中的目标页
2. 如果 k 是唯一索引，如果要更新目标页不在内存，则将数据页读入内存，判断没有冲突后更新；如果更新目标页在内存，则判断没有冲突后，更新目标页

可以看出来，唯一索引无法使用 change buffer。因此，如果业务中有大量插入数据的操作，普通索引相比唯一索引能够提高效率

change buffer 使用的是 buffer pool 中的内存，因此不能无限增大。change buffer 的大小可以通过参数 `innodb_change_buffer_max_size` 动态设置，如设置为 50 则表示其大小最多只能占用 buffer pool 的 50%

```sql
show variables like "innodb_change_buffer_max_size";
```

将 `change buffer` 应用到目标数据页的过程称之为 merge。除了访问目标数据页能触发 merge 外，系统在后台线程会定期 merge，当数据库关闭的过程中，也会有 merge 操作。可以看出，对于读多写少的业务来说，`change buffer` 会有很好的效果；反之，如果在写入之后马上查询，就会立即触发 merge，这样磁盘 IO 次数不会减少，反而增加了 `change buffer` 的维护代价

`change buffer` 主要是节省随机读磁盘的 IO 消耗（不用从磁盘读取目标数据页），`redo log` 主要节省的是随机写磁盘的 IO 消耗（转换为顺序写）

主键与唯一索引约束，执行 `insert` 和 `update` 时，会触发约束检查。在 InnoDB 中违反约束时，会进行回滚。可以指出在违反主键或唯一索引约束时，需要进行的额外操作：
```sql
insert into user(name) values("pain") on duplicate key update score = score + 10;
```

## 索引选择
选择索引是优化器的工作，优化器根据扫描行数，是否使用临时表，是否排序等因素进行综合考虑，选择最小的代价执行语句。其中，扫描行数是一个比较重要的因素。mysql 执行语句之前，并不能精确地知道满足这个条件的记录有多少条，而只能根据统计信息来估算记录数。这个统计信息就是索引的区分度，即索引上不同值的个数，也称为基数。基数越大，区分度越好。通过如下方式查看表中所有索引的基数
```sql
show index from t;
```
但是，由于 mysql 是通过采样统计估算出来索引基数的，我们得到的索引基数并不准确。mysql 默认选取 N 个数据页，统计这些页面上的不同值，得到一个平均值，然后乘以索引的页面数，其结果作为索引的基数。由于表中的数据是会持续更新的，当变更数据行数超过 1/M 的时候，会自动触发重新进行索引统计。在 mysql 中，有两种存储索引统计的方式，可以通过参数 `innodb_stats_persistent` 的值来选择：
1. 设置为 on 的时候，表示统计信息会持久话存储，此时默认 N 为 20，M 为 10
2. 设置为 off 的时候，表示统计信息只存储在内存中，此时默认 N 为 8，M 为 16

如果统计信息不准确，可以通过如下命令重新统计
```sql
analyze table t;
```

```sql
CREATE TABLE `t` (
  `id` int(11) NOT NULL,
  `a` int(11) DEFAULT NULL,
  `b` int(11) DEFAULT NULL,
  PRIMARY KEY (`id`),
  KEY `a` (`a`),
  KEY `b` (`b`)
) ENGINE=InnoDB；
```
```sql
delimiter ;;
create procedure idata()
begin
  declare i int;
  set i=1;
  while(i<=100000)do
    insert into t values(i, i, i);
    set i=i+1;
  end while;
end;;
delimiter ;
call idata();
```

```sql
select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
对于该查询，如果使用索引 a，就只需要扫描索引 a 的前 1000 个值，然后回表获取详细信息，再根据字段 b 进行过滤。这样只需要扫描 1000 行；如果使用索引 b，就要扫描索引 b 的后 50000 个值，再进行回表获取详细信息，最后根据字段 a 进行过滤。这样需要扫描 50000 行。结果却错误地选择了索引 b，可以通过如下方式纠正：

1. 采用 `force index` 强行选择一个索引
```sql
select * from t force index(a) where (a between 1 and 1000)  and (b between 50000 and 100000) order by b limit 1;
```
2. 改造 sql 语句
之前的优化器之所以会选择索引 b，是因为它认为索引 b 可以避免排序（因为索引 b 的索引树中字段 b 本身就是有序的），即使扫描行数多，代价也会小些。如果改成 `order by b, a`，意味着两个字段都需要排序，扫描行数就成为了影响优化器选择的主要因素，于是就会选择索引 a。但是该方法并不通用，只不过在 sql 语句中刚好有 limit 1，因此改动前后效果是一样的
```sql
select * from t where (a between 1 and 1000)  and (b between 50000 and 100000) order by b, a limit 1;
```
3. 新建一个更合适的索引，或者删除误用的索引

我们可以看出，虽然扫描行数是比较重要的因素，但有时候可能会考虑其他因素而选择扫描行数更多的索引。比如说，因为有排序选择需要排序字段上的索引；或者因为从索引上获取一个值，都要回到主键索引上查出整行数据，而直接从主键索引上面扫描不需要回表，可能就会选择主键扫描

### 字符串索引
非前缀索引，创建的索引中包含了记录的整个字符串
```sql
alter table user add index index_email(email);
```
前缀索引，创建的索引中只包含每个记录的前 6 个字符
```sql
alter table user add index index_email(email(6));
```

```sql
select * from user where email = "abc@qq.com";
```
对上面的查询语句，使用非前缀索引执行过程如下：
1. 从 email 索引树上面找到满足 `email = "abc@qq.com"` 的记录，获取 id
2. 到主键索引树上面找到记录，将记录加入到结果集中
3. 取 email 索引树中下一条记录，循环直到条件不满足为止

如果使用前缀索引执行过程如下：
1. 从 email 索引树上面找到满足 `email = "abc@qq"` 的记录，获取 id
2. 到主键索引树上面找到记录，判断 email 值是否正确，若正确将记录加入到结果集中
3. 取 email 索引树中下一条记录，循环直到条件不满足为止

可以发现，前缀索引占用的空间小，但可能会增加额外的记录扫描次数。因此在使用前缀索引是，需要定义好长度，才能做到既节省空间又不用额外增加太多的查询成本。我们可以根据区分度来选择合适的长度建立索引，即统计索引上有多少个不同的值来判断要使用多长的前缀

```sql
select
count(distinct email) as L
count(distinct left(email, 4)) as L4,
count(distinct left(email, 5)) as L5,
count(distinct left(email, 6)) as L6,
count(distinct left(email, 7)) as L7
from user;
```
预先设置一个可以接受的损失比例，比如 5%，找出不小于 L * 95% 的值即可

另外，前缀索引还会影响覆盖索引。比如运行如下语句，使用非前缀索引是能够应用覆盖索引的，但如果使用前缀索引，由于根据 email 前缀索引获取的到数据不完整，还是要根据获取的 id 到主键索引中获取详细信息，覆盖索引就用不到了
```sql
select id, email from user where email='pain@gmail.com';
```

对于类似于邮箱这样的字段来说，使用前缀索引的效果可能不错。但有的字段前缀的区分度可能不够好。例如：身份证号一共 18 位，其中前 6 位为地址码，如果是同一个市的数据，则选择长度为 6 的前缀区分度太低，但要加长前缀长度，又会占用过多的磁盘空间，相同的数据页能放下的索引值就越少，搜索的效率也就会越低。这时候可以采取以下方案：
1. 倒序存储
由于身份证的后 6 位没有地址码那样的重复逻辑，在存储身份证号的时候将身份证倒序存储，在查询的时候，就可以使用前缀索引了
```sql
select * from user where id_card=reverse('input_id_card');
```

2. hash 字段
在表上再创建一个整数字段，来保存身份证的校验码，同时在该字段上创建索引
```sql
alter table user add id_card_crc int unsigned, add index(id_card_crc);
```
这样索引长度变成了 4 个字节，节省了空间
```sql
select * from user where id_card_crc=crc32('input_id_card') and id_card='input_id_card';
```

需要注意的是，使用倒序存储与 hash 字段都无法进行范围查询。另外两者还有以下区别：
1. 从占用空间角度考虑，倒序存储方式在主键索引上，不会消耗额外的存储空间，而 hash 字段方法需要增加一个字段。不过，倒序存储方式使用 4 个字节的前缀长度应该是不够的，如果再长一点，这个消耗跟额外这个 hash 字段也差不多抵消了
2. 在 CPU 消耗方面，倒序方式每次写和读的时候，都需要额外调用一次 reverse 函数，而 hash 字段的方式需要额外调用一次 crc32() 函数。如果只从这两个函数的计算复杂度来看的话，reverse 函数额外消耗的 CPU 资源会更小些
3. 从查询效率上看，使用 hash 字段方式的查询性能相对更稳定一些。因为 crc32 算出来的值虽然有冲突的概率，但是概率非常小，可以认为每次查询的平均扫描行数接近 1。而倒序存储方式毕竟还是用的前缀索引的方式，也就是说还是会增加扫描行数

## 空间优化
表数据是存在共享表空间还是单独的文件，由参数 `innodb_file_per_table` 控制
```sql
show variables like "innodb_file_per_table";
```
设置为 off 表示表的的数据放在系统共享表空间，设置为 on 表示每个表数据存储在一个以 .idb 为后缀的文件中。从 5.6.6 版本开始，默认设置为 on。当用 `drop table` 删除表时，如果参数设置为 on 就会直接删除掉对应的文件，如果参数设置为 off，即使表删除了，空间也不会释放。因此，推荐将该参数设置为 on

### 数据空洞
数据表在大量增删改查操作之后，可能会存在大量空洞（可以复用但却没有使用的表空间），具体情况如下：
1. 数据删除
当删除一条记录时，innodb 只会将对应记录标记为删除，磁盘文件大小不会缩小，标记为删除的记录可以后续插入操作的时候复用。当删除一个数据页上的所有记录，整个数据页都可以复用了

记录的复用，只限于符合范围条件的数据，也就是说后续插入的记录不在对应范围，就无法复用；而当数据页从 B+ 树中摘掉之后，可以复用到任何位置。如果相邻的两个数据页利用率都很小，系统就会把这两个页上的数据合到其中一个数据页上，另外一个数据页就可以标记为可复用，但磁盘上文件大小并不会变小

可以看出 delete 命令其实只是将记录的位置，或者数据页标记为可复用，磁盘文件大小并不会改变，也就是说 delete 命令不能回收表空间，也就是会产生数据空洞

2. 数据插入
数据插入也会造成空洞：数据只有按照索引递增顺序插入才是紧凑的，如果是随机插入的，就会造成数据页分裂。数据页一旦分裂，就会产生空洞

3. 数据更新
更新索引上的值，可以理解为删除一个旧的值，再插入一个新值，同样有可能造成空洞

### 重建表
要取出数据空洞，达到收缩表空间的目的，需要通过重建表实现

```sql
alter table user engine=InnoDB;
```
在 5.5 版本之前，mysql 会自动完成转存数据、交互表名、删除旧表操作，在往临时表中插入数据的过程比较耗时，如果在这个过程中有数据写入，就会造成数据丢失；在 5.6 版本开始，引入 online ddl，在重建表的过程中，允许对表的增删改操作

在 alter 语句启动的时候需要获取 MDL 写锁，到真正拷贝数据的时候退化为读锁以支持 online，同时禁止了其他线程对这个表做 ddl 操作

### 重建普通索引
```sql
alter table user drop index k;
alter table user add index(k);
```

### 重建主键索引
以下重建索引的方式是错误的。这是因为普通索引中存储的是主键的键值，如果删除主键索引，会导致普通索引都会失效，并且使用 `row id` 来做主键索引。因此以下重建主键索引的方式会导致普通索引也会重新构造，性能开销比较大
```sql
alter table user drop primary key;
alter table user add primary key(id);
```
正确的重建索引方式是这样的：
```sql
alter table user engine=InnoDB;
```